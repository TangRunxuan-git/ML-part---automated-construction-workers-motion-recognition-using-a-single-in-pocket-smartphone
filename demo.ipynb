{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from feature_engine.timeseries.forecasting import WindowFeatures\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 定义滑窗长度列表\n",
    "window_lengths = [0.6, 0.8, 1]\n",
    "\n",
    "# 定义要处理的主题\n",
    "train_subjects = ['Carpenter1', 'Carpenter2', 'Rebar1', 'Rebar2', 'Rebar3']\n",
    "test_subjects = ['Masonry1', 'Masonry2']\n",
    "\n",
    "# 初始化空数据框存储所有主题的数据\n",
    "all_train_data = []\n",
    "all_test_data = []\n",
    "\n",
    "# 首先，我们定义一个函数来过滤出非数值型的列名\n",
    "def get_numeric_columns(df):\n",
    "    return [col for col in df.columns if df[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "# 遍历每个主题文件\n",
    "for subject in train_subjects + test_subjects:\n",
    "    # 读取数据\n",
    "    df = pd.read_csv(f'../{subject}.csv')\n",
    "    \n",
    "    # 只选取前八个动作\n",
    "    df = df[df['Label_2'] <= 8]\n",
    "    \n",
    "    # 重新编码标签\n",
    "    label_mapping = {1: 1, 2: 2, 3: 3, 4: 3, 5: 4, 6: 3, 7: 3, 8: 5}\n",
    "    df['Label_2'] = df['Label_2'].map(label_mapping)\n",
    "    \n",
    "    # 同步 xd 和 kd 的记录\n",
    "    df_xd = df[df['position'] == 'xd'].copy()\n",
    "    df_kd = df[df['position'] == 'kd'].copy()\n",
    "\n",
    "    # 确保 xd 和 kd 有相同的时间戳\n",
    "    common_times = set(df_xd['seconds_elapsed']).intersection(set(df_kd['seconds_elapsed']))\n",
    "    df_xd = df_xd[df_xd['seconds_elapsed'].isin(common_times)]\n",
    "    df_kd = df_kd[df_kd['seconds_elapsed'].isin(common_times)]\n",
    "\n",
    "    # 将 xd 和 kd 的数据合并为一个数据单元\n",
    "    df_combined = pd.merge(df_xd, df_kd, on='seconds_elapsed', suffixes=('_xd', '_kd'))\n",
    "\n",
    "    # 在合并 df_xd 和 df_kd 之后，检查并转换数据类型\n",
    "    for col in df_combined.columns:\n",
    "        if df_combined[col].dtype == 'object':\n",
    "            # 尝试将非数值列转换为数值\n",
    "            try:\n",
    "                df_combined[col] = pd.to_numeric(df_combined[col], errors='raise')\n",
    "            except ValueError:\n",
    "                # 如果转换失败，打印警告并删除这些列\n",
    "                print(f\"Warning: Column {col} could not be converted to a numeric type and will be dropped.\")\n",
    "                df_combined.drop(columns=[col], inplace=True)\n",
    "\n",
    "    # 删除包含NaN的行\n",
    "    df_combined.dropna(inplace=True)\n",
    "\n",
    "    # 检查并替换inf值为NaN，然后删除包含NaN的行\n",
    "    df_combined.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_combined.dropna(inplace=True)\n",
    "\n",
    "    # 获取数值型列列表，排除特定的非数值型列\n",
    "    numeric_columns = get_numeric_columns(df_combined)\n",
    "    exclude_columns = ['seconds_elapsed', 'time_xd', 'Real Time_xd', 'Label_2_xd']\n",
    "    numeric_columns = [col for col in numeric_columns if col not in exclude_columns]\n",
    "\n",
    "    # 设置合理的数值范围（可以根据实际情况调整）\n",
    "    lower_bound = -10000\n",
    "    upper_bound = 10000\n",
    "\n",
    "    # 创建一个新的空DataFrame来存储筛选后的结果\n",
    "    df_filtered = pd.DataFrame()\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        # 使用 & 操作符组合多个条件，并筛选出符合条件的行\n",
    "        filtered_rows = df_combined[(df_combined[col] >= lower_bound) & (df_combined[col] <= upper_bound)]\n",
    "        # 将筛选后的结果追加到新的DataFrame中\n",
    "        df_filtered = pd.concat([df_filtered, filtered_rows], ignore_index=True)\n",
    "\n",
    "    # 如果你想要替换原来的DataFrame\n",
    "    df_combined = df_filtered\n",
    "\n",
    "    # # 设置合理的 chunksize\n",
    "    # chunksize = 1000  # 你可以根据实际情况调整这个值\n",
    "\n",
    "    # # 使用 tsfresh 提取特征\n",
    "    # extracted_features = extract_features(\n",
    "    #     df_combined,\n",
    "    #     column_id=\"seconds_elapsed\",\n",
    "    #     column_sort=\"seconds_elapsed\",\n",
    "    #     chunksize=chunksize  # 显式设置 chunksize\n",
    "    # )\n",
    "        \n",
    "    impute(df_combined)\n",
    "    # target = df_combined[['Label_2_xd']].drop_duplicates().set_index('seconds_elapsed')\n",
    "    target = df_combined[['Label_2_xd']].drop_duplicates()\n",
    "    # relevant_features_tsfresh = select_features(df_combined, target)\n",
    "\n",
    "    # 创建不同滑窗长度的特征\n",
    "    for window_length in window_lengths:\n",
    "        window_features = WindowFeatures(\n",
    "            variables=[col for col in df_combined.columns if col not in ['seconds_elapsed', 'time_xd', 'Real Time_xd', 'Label_2_xd']],\n",
    "            window=f'{window_length}s',\n",
    "            freq='1s'\n",
    "        )\n",
    "        df_combined = pd.concat([df_combined, window_features.fit_transform(df_combined)], axis=1)\n",
    "\n",
    "    # 合并所有特征\n",
    "    # all_features = pd.concat([df_combined, relevant_features_tsfresh], axis=1).dropna()\n",
    "\n",
    "    # 分离特征和目标变量\n",
    "    X = df_combined.drop(columns=['seconds_elapsed', 'time_xd', 'Real Time_xd', 'Label_2_xd'])\n",
    "    y = df_combined['Label_2_xd']\n",
    "\n",
    "    if subject in train_subjects:\n",
    "        all_train_data.append((X, y))\n",
    "    else:\n",
    "        all_test_data.append((X, y))\n",
    "\n",
    "# 合并训练数据和测试数据\n",
    "X_train_all, y_train_all = pd.concat([data[0] for data in all_train_data]), pd.concat([data[1] for data in all_train_data])\n",
    "X_test_all, y_test_all = pd.concat([data[0] for data in all_test_data]), pd.concat([data[1] for data in all_test_data])\n",
    "\n",
    "# 使用SMOTE处理类别不平衡\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_all, y_train_all)\n",
    "\n",
    "# 划分训练集和验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# 定义XGBoost和LightGBM的参数空间\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'tree_method': 'gpu_hist',\n",
    "}\n",
    "\n",
    "lgbm_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'num_leaves': [31, 50, 100],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'tree_method': 'gpu_hist',\n",
    "}\n",
    "\n",
    "# 使用 RandomizedSearchCV 进行XGBoost模型调优\n",
    "xgb_clf = XGBClassifier(n_jobs=-1, random_state=42)\n",
    "xgb_random_search = RandomizedSearchCV(xgb_clf, xgb_param_grid, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "xgb_random_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best parameters for XGBoost:\", xgb_random_search.best_params_)\n",
    "best_xgb_clf = xgb_random_search.best_estimator_\n",
    "\n",
    "# 使用 RandomizedSearchCV 进行LightGBM模型调优\n",
    "lgbm_clf = LGBMClassifier(n_jobs=-1, random_state=42)\n",
    "lgbm_random_search = RandomizedSearchCV(lgbm_clf, lgbm_param_grid, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "lgbm_random_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best parameters for LightGBM:\", lgbm_random_search.best_params_)\n",
    "best_lgbm_clf = lgbm_random_search.best_estimator_\n",
    "\n",
    "# 在验证集上评估XGBoost模型\n",
    "y_pred_xgb = best_xgb_clf.predict(X_val)\n",
    "print(\"XGBoost Validation Accuracy:\", accuracy_score(y_val, y_pred_xgb))\n",
    "print(\"XGBoost Classification Report:\\n\", classification_report(y_val, y_pred_xgb))\n",
    "\n",
    "# 在验证集上评估LightGBM模型\n",
    "y_pred_lgbm = best_lgbm_clf.predict(X_val)\n",
    "print(\"LightGBM Validation Accuracy:\", accuracy_score(y_val, y_pred_lgbm))\n",
    "print(\"LightGBM Classification Report:\\n\", classification_report(y_val, y_pred_lgbm))\n",
    "\n",
    "# 对测试集进行预测\n",
    "y_pred_xgb_test = best_xgb_clf.predict(X_test_all)\n",
    "print(\"XGBoost Test Accuracy:\", accuracy_score(y_test_all, y_pred_xgb_test))\n",
    "print(\"XGBoost Test Classification Report:\\n\", classification_report(y_test_all, y_pred_xgb_test))\n",
    "\n",
    "y_pred_lgbm_test = best_lgbm_clf.predict(X_test_all)\n",
    "print(\"LightGBM Test Accuracy:\", accuracy_score(y_test_all, y_pred_lgbm_test))\n",
    "print(\"LightGBM Test Classification Report:\\n\", classification_report(y_test_all, y_pred_lgbm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "from feature_engine.timeseries.forecasting import WindowFeatures\n",
    "from feature_engine.selection import SelectByShuffling\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 定义滑窗长度列表\n",
    "window_lengths = [0.6, 0.8, 1]\n",
    "\n",
    "# 定义要处理的主题\n",
    "train_subjects = ['Carpenter1', 'Carpenter2', 'Rebar1', 'Rebar2', 'Rebar3']\n",
    "test_subjects = ['Masonry1', 'Masonry2']\n",
    "\n",
    "# 初始化空数据框存储所有主题的数据\n",
    "all_train_data = []\n",
    "all_test_data = []\n",
    "\n",
    "# 首先，我们定义一个函数来过滤出非数值型的列名\n",
    "def get_numeric_columns(df):\n",
    "    return [col for col in df.columns if df[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "# 遍历每个主题文件\n",
    "for subject in train_subjects + test_subjects:\n",
    "    # 读取数据\n",
    "    df = pd.read_csv(f'../{subject}.csv')\n",
    "    \n",
    "    # 只选取前八个动作\n",
    "    df = df[df['Label_2'] <= 8]\n",
    "    \n",
    "    # 重新编码标签\n",
    "    label_mapping = {1: 1, 2: 2, 3: 3, 4: 3, 5: 4, 6: 3, 7: 3, 8: 5}\n",
    "    df['Label_2'] = df['Label_2'].map(label_mapping)\n",
    "    \n",
    "    # 同步 xd 和 kd 的记录\n",
    "    df_xd = df[df['position'] == 'xd'].copy()\n",
    "    df_kd = df[df['position'] == 'kd'].copy()\n",
    "\n",
    "    # 确保 xd 和 kd 有相同的时间戳\n",
    "    common_times = set(df_xd['seconds_elapsed']).intersection(set(df_kd['seconds_elapsed']))\n",
    "    df_xd = df_xd[df_xd['seconds_elapsed'].isin(common_times)]\n",
    "    df_kd = df_kd[df_kd['seconds_elapsed'].isin(common_times)]\n",
    "\n",
    "    # 将 xd 和 kd 的数据合并为一个数据单元\n",
    "    df_combined = pd.merge(df_xd, df_kd, on='seconds_elapsed', suffixes=('_xd', '_kd'))\n",
    "\n",
    "    # 在合并 df_xd 和 df_kd 之后，检查并转换数据类型\n",
    "    for col in df_combined.columns:\n",
    "        if df_combined[col].dtype == 'object':\n",
    "            # 尝试将非数值列转换为数值\n",
    "            try:\n",
    "                df_combined[col] = pd.to_numeric(df_combined[col], errors='raise')\n",
    "            except ValueError:\n",
    "                # 如果转换失败，打印警告并删除这些列\n",
    "                print(f\"Warning: Column {col} could not be converted to a numeric type and will be dropped.\")\n",
    "                df_combined.drop(columns=[col], inplace=True)\n",
    "\n",
    "    # 删除包含NaN的行\n",
    "    df_combined.dropna(inplace=True)\n",
    "\n",
    "    # 检查并替换inf值为NaN，然后删除包含NaN的行\n",
    "    df_combined.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_combined.dropna(inplace=True)\n",
    "\n",
    "    # 获取数值型列列表，排除特定的非数值型列\n",
    "    numeric_columns = get_numeric_columns(df_combined)\n",
    "    exclude_columns = ['seconds_elapsed', 'time_xd', 'Real Time_xd', 'Label_2_xd']\n",
    "    numeric_columns = [col for col in numeric_columns if col not in exclude_columns]\n",
    "\n",
    "    # 创建不同滑窗长度的特征\n",
    "    for window_length in window_lengths:\n",
    "        window_features = WindowFeatures(\n",
    "            variables=[col for col in df_combined.columns if col not in ['seconds_elapsed', 'time_xd', 'Real Time_xd', 'Label_2_xd']],\n",
    "            window=f'{window_length}s',\n",
    "            freq='1s'\n",
    "        )\n",
    "        df_combined = pd.concat([df_combined, window_features.fit_transform(df_combined)], axis=1)\n",
    "\n",
    "    # 合并所有特征\n",
    "    all_features = df_combined\n",
    "\n",
    "    # 分离特征和目标变量\n",
    "    X = all_features.drop(columns=['seconds_elapsed', 'time_xd', 'Real Time_xd', 'Label_2_xd'])\n",
    "    y = all_features['Label_2_xd']\n",
    "\n",
    "    if subject in train_subjects:\n",
    "        all_train_data.append((X, y))\n",
    "    else:\n",
    "        all_test_data.append((X, y))\n",
    "\n",
    "# 合并训练数据和测试数据\n",
    "X_train_all, y_train_all = pd.concat([data[0] for data in all_train_data]), pd.concat([data[1] for data in all_train_data])\n",
    "X_test_all, y_test_all = pd.concat([data[0] for data in all_test_data]), pd.concat([data[1] for data in all_test_data])\n",
    "\n",
    "# 使用SMOTE处理类别不平衡\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_all, y_train_all)\n",
    "\n",
    "# 划分训练集和验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# 定义XGBoost和LightGBM的参数空间\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'tree_method': 'gpu_hist',\n",
    "}\n",
    "\n",
    "lgbm_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'num_leaves': [31, 50, 100],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'tree_method': 'gpu_hist',\n",
    "}\n",
    "\n",
    "# 使用 RandomizedSearchCV 进行XGBoost模型调优\n",
    "xgb_clf = XGBClassifier(n_jobs=-1, random_state=42)\n",
    "xgb_random_search = RandomizedSearchCV(xgb_clf, xgb_param_grid, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "xgb_random_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best parameters for XGBoost:\", xgb_random_search.best_params_)\n",
    "best_xgb_clf = xgb_random_search.best_estimator_\n",
    "\n",
    "# 使用 RandomizedSearchCV 进行LightGBM模型调优\n",
    "lgbm_clf = LGBMClassifier(n_jobs=-1, random_state=42)\n",
    "lgbm_random_search = RandomizedSearchCV(lgbm_clf, lgbm_param_grid, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "lgbm_random_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best parameters for LightGBM:\", lgbm_random_search.best_params_)\n",
    "best_lgbm_clf = lgbm_random_search.best_estimator_\n",
    "\n",
    "# 在验证集上评估XGBoost模型\n",
    "y_pred_xgb = best_xgb_clf.predict(X_val)\n",
    "print(\"XGBoost Validation Accuracy:\", accuracy_score(y_val, y_pred_xgb))\n",
    "print(\"XGBoost Classification Report:\\n\", classification_report(y_val, y_pred_xgb))\n",
    "\n",
    "# 在验证集上评估LightGBM模型\n",
    "y_pred_lgbm = best_lgbm_clf.predict(X_val)\n",
    "print(\"LightGBM Validation Accuracy:\", accuracy_score(y_val, y_pred_lgbm))\n",
    "print(\"LightGBM Classification Report:\\n\", classification_report(y_val, y_pred_lgbm))\n",
    "\n",
    "# 对测试集进行预测\n",
    "y_pred_xgb_test = best_xgb_clf.predict(X_test_all)\n",
    "print(\"XGBoost Test Accuracy:\", accuracy_score(y_test_all, y_pred_xgb_test))\n",
    "print(\"XGBoost Test Classification Report:\\n\", classification_report(y_test_all, y_pred_xgb_test))\n",
    "\n",
    "y_pred_lgbm_test = best_lgbm_clf.predict(X_test_all)\n",
    "print(\"LightGBM Test Accuracy:\", accuracy_score(y_test_all, y_pred_lgbm_test))\n",
    "print(\"LightGBM Test Classification Report:\\n\", classification_report(y_test_all, y_pred_lgbm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python3.9.0\\PYTHON\\lib\\site-packages\\sklearn\\impute\\_base.py:577: UserWarning: Skipping features without any observed values: ['Accelerometer.xlsx_z_xd_std_1' 'Accelerometer.xlsx_y_xd_std_1'\n",
      " 'Accelerometer.xlsx_x_xd_std_1' 'Gravity_z_xd_std_1' 'Gravity_y_xd_std_1'\n",
      " 'Gravity_x_xd_std_1' 'Gyroscope_z_xd_std_1' 'Gyroscope_y_xd_std_1'\n",
      " 'Gyroscope_x_xd_std_1' 'Magnetometer_z_xd_std_1'\n",
      " 'Magnetometer_y_xd_std_1' 'Magnetometer_x_xd_std_1' 'yaw_xd_std_1'\n",
      " 'qx_xd_std_1' 'qz_xd_std_1' 'roll_xd_std_1' 'qw_xd_std_1' 'qy_xd_std_1'\n",
      " 'pitch_xd_std_1' 'time_xd_std_1' 'Accelerometer.xlsx_z_kd_std_1'\n",
      " 'Accelerometer.xlsx_y_kd_std_1' 'Accelerometer.xlsx_x_kd_std_1'\n",
      " 'Gravity_z_kd_std_1' 'Gravity_y_kd_std_1' 'Gravity_x_kd_std_1'\n",
      " 'Gyroscope_z_kd_std_1' 'Gyroscope_y_kd_std_1' 'Gyroscope_x_kd_std_1'\n",
      " 'Magnetometer_z_kd_std_1' 'Magnetometer_y_kd_std_1'\n",
      " 'Magnetometer_x_kd_std_1' 'yaw_kd_std_1' 'qx_kd_std_1' 'qz_kd_std_1'\n",
      " 'roll_kd_std_1' 'qw_kd_std_1' 'qy_kd_std_1' 'pitch_kd_std_1'\n",
      " 'time_kd_std_1' 'Label_2_kd_std_1']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "d:\\python3.9.0\\PYTHON\\lib\\site-packages\\sklearn\\impute\\_base.py:577: UserWarning: Skipping features without any observed values: ['Accelerometer.xlsx_z_xd_std_1' 'Accelerometer.xlsx_y_xd_std_1'\n",
      " 'Accelerometer.xlsx_x_xd_std_1' 'Gravity_z_xd_std_1' 'Gravity_y_xd_std_1'\n",
      " 'Gravity_x_xd_std_1' 'Gyroscope_z_xd_std_1' 'Gyroscope_y_xd_std_1'\n",
      " 'Gyroscope_x_xd_std_1' 'Magnetometer_z_xd_std_1'\n",
      " 'Magnetometer_y_xd_std_1' 'Magnetometer_x_xd_std_1' 'yaw_xd_std_1'\n",
      " 'qx_xd_std_1' 'qz_xd_std_1' 'roll_xd_std_1' 'qw_xd_std_1' 'qy_xd_std_1'\n",
      " 'pitch_xd_std_1' 'time_xd_std_1' 'Accelerometer.xlsx_z_kd_std_1'\n",
      " 'Accelerometer.xlsx_y_kd_std_1' 'Accelerometer.xlsx_x_kd_std_1'\n",
      " 'Gravity_z_kd_std_1' 'Gravity_y_kd_std_1' 'Gravity_x_kd_std_1'\n",
      " 'Gyroscope_z_kd_std_1' 'Gyroscope_y_kd_std_1' 'Gyroscope_x_kd_std_1'\n",
      " 'Magnetometer_z_kd_std_1' 'Magnetometer_y_kd_std_1'\n",
      " 'Magnetometer_x_kd_std_1' 'yaw_kd_std_1' 'qx_kd_std_1' 'qz_kd_std_1'\n",
      " 'roll_kd_std_1' 'qw_kd_std_1' 'qy_kd_std_1' 'pitch_kd_std_1'\n",
      " 'time_kd_std_1' 'Label_2_kd_std_1']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 定义滑窗长度列表（假设采样频率为1Hz）\n",
    "sampling_frequency = 1  # 每秒一个样本\n",
    "window_lengths = [max(int(0.6 * sampling_frequency), 1), max(int(0.8 * sampling_frequency), 1), max(int(1 * sampling_frequency), 1)]\n",
    "\n",
    "# 定义要处理的主题\n",
    "train_subjects = ['Carpenter1', 'Carpenter2', 'Rebar1', 'Rebar2', 'Rebar3']\n",
    "test_subjects = ['Masonry1', 'Masonry2']\n",
    "\n",
    "# 初始化空数据框存储所有主题的数据\n",
    "all_train_data = []\n",
    "all_test_data = []\n",
    "\n",
    "# 遍历每个主题文件\n",
    "for subject in train_subjects + test_subjects:\n",
    "    # 读取数据，设置 low_memory=False\n",
    "    df = pd.read_csv(f'../{subject}.csv', low_memory=False)\n",
    "    \n",
    "    # 将 'Label_2' 列转换为数值类型\n",
    "    df['Label_2'] = pd.to_numeric(df['Label_2'], errors='coerce')\n",
    "    \n",
    "    # 只选取前八个动作\n",
    "    df = df[df['Label_2'] <= 8]\n",
    "    \n",
    "    # 重新编码标签\n",
    "    label_mapping = {1: 1, 2: 2, 3: 3, 4: 3, 5: 4, 6: 3, 7: 3, 8: 5}\n",
    "    df['Label_2'] = df['Label_2'].map(label_mapping)\n",
    "    \n",
    "    # 同步 xd 和 kd 的记录\n",
    "    df_xd = df[df['position'] == 'xd'].copy()\n",
    "    df_kd = df[df['position'] == 'kd'].copy()\n",
    "\n",
    "    # 确保 xd 和 kd 有相同的时间戳\n",
    "    common_times = set(df_xd['seconds_elapsed']).intersection(set(df_kd['seconds_elapsed']))\n",
    "    df_xd = df_xd[df_xd['seconds_elapsed'].isin(common_times)]\n",
    "    df_kd = df_kd[df_kd['seconds_elapsed'].isin(common_times)]\n",
    "\n",
    "    # 将 xd 和 kd 的数据合并为一个数据单元\n",
    "    df_combined = pd.merge(df_xd, df_kd, on='seconds_elapsed', suffixes=('_xd', '_kd'))\n",
    "\n",
    "    # 删除非数值列\n",
    "    df_combined = df_combined.select_dtypes(include=[np.number])\n",
    "\n",
    "    # 删除包含NaN的行\n",
    "    df_combined.dropna(inplace=True)\n",
    "\n",
    "    # 检查并替换inf值为NaN，然后删除包含NaN的行\n",
    "    df_combined.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_combined.dropna(inplace=True)\n",
    "\n",
    "    # 创建不同滑窗长度的特征\n",
    "    new_features = {}\n",
    "    for window_length in window_lengths:\n",
    "        for col in df_combined.columns:\n",
    "            if col not in ['seconds_elapsed', 'Label_2_xd']:\n",
    "                # 确保窗口大小至少为1\n",
    "                window_length = max(window_length, 1)\n",
    "                new_features[f'{col}_mean_{window_length}'] = df_combined[col].rolling(window=window_length, min_periods=1).mean()\n",
    "                new_features[f'{col}_std_{window_length}'] = df_combined[col].rolling(window=window_length, min_periods=1).std()\n",
    "\n",
    "    # 一次性将所有新特征添加到 DataFrame 中\n",
    "    df_combined = pd.concat([df_combined, pd.DataFrame(new_features)], axis=1)\n",
    "\n",
    "    # 分离特征和目标变量\n",
    "    X = df_combined.drop(columns=['seconds_elapsed', 'Label_2_xd'])\n",
    "    y = df_combined['Label_2_xd']\n",
    "\n",
    "    if subject in train_subjects:\n",
    "        all_train_data.append((X, y))\n",
    "    else:\n",
    "        all_test_data.append((X, y))\n",
    "\n",
    "# 合并训练数据和测试数据\n",
    "X_train_all, y_train_all = pd.concat([data[0] for data in all_train_data]), pd.concat([data[1] for data in all_train_data])\n",
    "X_test_all, y_test_all = pd.concat([data[0] for data in all_test_data]), pd.concat([data[1] for data in all_test_data])\n",
    "\n",
    "# 使用 SimpleImputer 处理缺失值\n",
    "imputer = SimpleImputer(strategy='mean')  # 也可以选择其他策略，如 'median' 或 'most_frequent'\n",
    "X_train_imputed = imputer.fit_transform(X_train_all)\n",
    "X_test_imputed = imputer.transform(X_test_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 使用 SMOTE 处理类别不平衡，并设置 n_neighbors 为 2\n",
    "# smote = SMOTE(random_state=42, k_neighbors=2)\n",
    "# X_resampled, y_resampled = smote.fit_resample(X_train_imputed, y_train_all)\n",
    "\n",
    "# 输出结果\n",
    "# print(\"Resampled training data shape:\", X_resampled.shape, y_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.08363057e-01,  8.01913179e-01, -8.36096896e-01,\n",
       "        -2.51921628e+00, -8.80946968e+00,  3.49530646e+00,\n",
       "         3.50175200e-03,  1.36099130e-01, -2.36295402e-01,\n",
       "         1.51912842e+01, -6.44863968e+01,  2.73372650e+01,\n",
       "        -5.48659956e-01,  5.58392365e-01,  2.76756300e-02,\n",
       "         9.46284364e-01,  7.92261506e-01,  2.44445664e-01,\n",
       "         1.11592127e+00,  1.63288000e+18, -4.39467120e-02,\n",
       "        -2.85357740e-02,  9.60492210e-02,  2.08847205e-01,\n",
       "        -9.00688143e+00, -3.87335067e+00, -2.17964370e-02,\n",
       "        -4.28508070e-02, -8.99861530e-02,  4.21420288e+01,\n",
       "        -4.67664719e+01, -7.88182545e+00,  3.08764323e+00,\n",
       "         6.16336533e-01,  5.63572813e-01, -1.62466317e+00,\n",
       "         4.14412132e-01,  3.61631749e-01,  1.16413445e+00,\n",
       "         1.63288000e+18,  1.00000000e+00,  2.08363057e-01,\n",
       "         8.01913179e-01, -8.36096896e-01, -2.51921628e+00,\n",
       "        -8.80946968e+00,  3.49530646e+00,  3.50175200e-03,\n",
       "         1.36099130e-01, -2.36295402e-01,  1.51912842e+01,\n",
       "        -6.44863968e+01,  2.73372650e+01, -5.48659956e-01,\n",
       "         5.58392365e-01,  2.76756300e-02,  9.46284364e-01,\n",
       "         7.92261506e-01,  2.44445664e-01,  1.11592127e+00,\n",
       "         1.63288000e+18, -4.39467120e-02, -2.85357740e-02,\n",
       "         9.60492210e-02,  2.08847205e-01, -9.00688143e+00,\n",
       "        -3.87335067e+00, -2.17964370e-02, -4.28508070e-02,\n",
       "        -8.99861530e-02,  4.21420288e+01, -4.67664719e+01,\n",
       "        -7.88182545e+00,  3.08764323e+00,  6.16336533e-01,\n",
       "         5.63572813e-01, -1.62466317e+00,  4.14412132e-01,\n",
       "         3.61631749e-01,  1.16413445e+00,  1.63288000e+18,\n",
       "         1.00000000e+00],\n",
       "       [-6.98275690e-02, -1.01830143e-01,  1.63582542e-01,\n",
       "         5.65340512e+00, -6.76249624e+00,  4.29861139e+00,\n",
       "         1.18453264e-01, -1.03951220e-02,  6.15178530e-02,\n",
       "         3.00261230e+01, -6.33920212e+01, -1.63133469e+01,\n",
       "         1.02714437e+00, -3.28983365e-01,  4.52179750e-01,\n",
       "         2.49149537e+00,  8.53820870e-02,  8.24629241e-01,\n",
       "         7.60912700e-01,  1.63288000e+18,  5.73818709e-01,\n",
       "        -2.68194133e-01,  1.14221420e-02, -7.64778679e+00,\n",
       "         5.92309183e-01, -6.10990268e+00,  8.66308600e-03,\n",
       "        -4.33528570e-02, -2.68094870e-02,  1.52725220e+01,\n",
       "         4.11681976e+01, -8.81829224e+01, -1.70374753e+00,\n",
       "         2.67516593e-01,  7.03273637e-01, -6.74076711e-01,\n",
       "        -6.28756623e-01,  1.96230115e-01, -6.04355090e-02,\n",
       "         1.63288000e+18,  5.00000000e+00, -6.98275690e-02,\n",
       "        -1.01830143e-01,  1.63582542e-01,  5.65340512e+00,\n",
       "        -6.76249624e+00,  4.29861139e+00,  1.18453264e-01,\n",
       "        -1.03951220e-02,  6.15178530e-02,  3.00261230e+01,\n",
       "        -6.33920212e+01, -1.63133469e+01,  1.02714437e+00,\n",
       "        -3.28983365e-01,  4.52179750e-01,  2.49149537e+00,\n",
       "         8.53820870e-02,  8.24629241e-01,  7.60912700e-01,\n",
       "         1.63288000e+18,  5.73818709e-01, -2.68194133e-01,\n",
       "         1.14221420e-02, -7.64778679e+00,  5.92309183e-01,\n",
       "        -6.10990268e+00,  8.66308600e-03, -4.33528570e-02,\n",
       "        -2.68094870e-02,  1.52725220e+01,  4.11681976e+01,\n",
       "        -8.81829224e+01, -1.70374753e+00,  2.67516593e-01,\n",
       "         7.03273637e-01, -6.74076711e-01, -6.28756623e-01,\n",
       "         1.96230115e-01, -6.04355090e-02,  1.63288000e+18,\n",
       "         5.00000000e+00],\n",
       "       [-1.41056939e+00,  2.51499895e-01,  1.61593268e-01,\n",
       "        -2.41835717e+00, -9.43655412e+00,  1.12843200e+00,\n",
       "        -1.75484508e-01,  4.25843298e-01,  1.61242262e-01,\n",
       "        -1.00814743e+01, -5.53804169e+01,  2.25280762e+00,\n",
       "         3.41124445e-01, -4.33551023e-01,  4.28729750e-01,\n",
       "        -2.00737775e+00, -5.08583017e-01,  6.07920660e-01,\n",
       "         1.29519127e+00,  1.63280000e+18,  5.82431639e-01,\n",
       "        -4.94466356e-01, -1.19129068e-01, -9.30226372e+00,\n",
       "        -3.00899886e+00, -7.64331856e-01, -2.14247882e-01,\n",
       "         3.62232740e-02,  1.06200710e-01, -2.14319572e+01,\n",
       "        -1.66716805e+01, -7.89703369e+00, -1.96941372e+00,\n",
       "        -4.94436480e-01, -6.63508454e-01, -1.48881427e+00,\n",
       "         3.14207951e-01, -4.65362750e-01,  3.11863198e-01,\n",
       "         1.63280000e+18,  1.00000000e+00, -1.41056939e+00,\n",
       "         2.51499895e-01,  1.61593268e-01, -2.41835717e+00,\n",
       "        -9.43655412e+00,  1.12843200e+00, -1.75484508e-01,\n",
       "         4.25843298e-01,  1.61242262e-01, -1.00814743e+01,\n",
       "        -5.53804169e+01,  2.25280762e+00,  3.41124445e-01,\n",
       "        -4.33551023e-01,  4.28729750e-01, -2.00737775e+00,\n",
       "        -5.08583017e-01,  6.07920660e-01,  1.29519127e+00,\n",
       "         1.63280000e+18,  5.82431639e-01, -4.94466356e-01,\n",
       "        -1.19129068e-01, -9.30226372e+00, -3.00899886e+00,\n",
       "        -7.64331856e-01, -2.14247882e-01,  3.62232740e-02,\n",
       "         1.06200710e-01, -2.14319572e+01, -1.66716805e+01,\n",
       "        -7.89703369e+00, -1.96941372e+00, -4.94436480e-01,\n",
       "        -6.63508454e-01, -1.48881427e+00,  3.14207951e-01,\n",
       "        -4.65362750e-01,  3.11863198e-01,  1.63280000e+18,\n",
       "         1.00000000e+00],\n",
       "       [ 1.05237321e-01, -4.51397030e-02,  6.44700318e-01,\n",
       "         2.47526257e+00, -9.19168796e+00,  2.35717834e+00,\n",
       "         3.42560780e-02, -1.04358286e-01,  3.55679020e-02,\n",
       "         3.21256294e+01, -3.53208923e+01,  1.22963257e+01,\n",
       "        -2.12551372e+00, -7.68789550e-01,  2.74380770e-02,\n",
       "         2.33176363e+00, -6.15682017e-01, -1.70719884e-01,\n",
       "         1.21477601e+00,  1.63280000e+18,  2.60881179e-01,\n",
       "        -1.01048637e-01,  1.83109520e-02, -1.48880765e+00,\n",
       "        -9.62000690e+00, -1.18713049e+00, -2.37737670e-02,\n",
       "        -5.40130030e-02,  1.63624250e-02,  1.09087372e+00,\n",
       "        -5.05068474e+01, -2.86462402e+01, -1.12283783e-01,\n",
       "        -5.52171393e-01,  3.14058802e-01, -8.97661115e-01,\n",
       "        -6.79627646e-01,  3.66851391e-01,  1.37538407e+00,\n",
       "         1.63280000e+18,  1.00000000e+00,  1.05237321e-01,\n",
       "        -4.51397030e-02,  6.44700318e-01,  2.47526257e+00,\n",
       "        -9.19168796e+00,  2.35717834e+00,  3.42560780e-02,\n",
       "        -1.04358286e-01,  3.55679020e-02,  3.21256294e+01,\n",
       "        -3.53208923e+01,  1.22963257e+01, -2.12551372e+00,\n",
       "        -7.68789550e-01,  2.74380770e-02,  2.33176363e+00,\n",
       "        -6.15682017e-01, -1.70719884e-01,  1.21477601e+00,\n",
       "         1.63280000e+18,  2.60881179e-01, -1.01048637e-01,\n",
       "         1.83109520e-02, -1.48880765e+00, -9.62000690e+00,\n",
       "        -1.18713049e+00, -2.37737670e-02, -5.40130030e-02,\n",
       "         1.63624250e-02,  1.09087372e+00, -5.05068474e+01,\n",
       "        -2.86462402e+01, -1.12283783e-01, -5.52171393e-01,\n",
       "         3.14058802e-01, -8.97661115e-01, -6.79627646e-01,\n",
       "         3.66851391e-01,  1.37538407e+00,  1.63280000e+18,\n",
       "         1.00000000e+00],\n",
       "       [-3.18831120e-02, -5.02104000e-04, -1.36425363e-01,\n",
       "        -5.27312540e-01, -9.25817674e+00,  3.19038097e+00,\n",
       "        -6.35125790e-02,  6.49215650e-02,  2.48933170e-02,\n",
       "         1.86690636e+01, -5.61819611e+01,  1.09455566e+01,\n",
       "        -3.03199616e+00,  8.08849275e-01,  9.82074380e-02,\n",
       "        -2.97779152e+00,  5.72443287e-01,  9.17987150e-02,\n",
       "         1.23476673e+00,  1.63280000e+18, -6.21364300e-02,\n",
       "         1.27226669e-01, -7.19885470e-02, -4.71429559e+00,\n",
       "        -6.72220360e-02, -8.59891146e+00, -2.44880490e-02,\n",
       "         2.00129060e-02,  5.22153710e-02, -1.39453430e+01,\n",
       "         7.57501221e+00, -5.27445068e+01, -3.87761248e-01,\n",
       "        -4.45479990e-02, -1.87476418e-01, -5.01493490e-01,\n",
       "         9.50407829e-01, -2.44116765e-01,  6.85479400e-03,\n",
       "         1.63280000e+18,  5.00000000e+00, -3.18831120e-02,\n",
       "        -5.02104000e-04, -1.36425363e-01, -5.27312540e-01,\n",
       "        -9.25817674e+00,  3.19038097e+00, -6.35125790e-02,\n",
       "         6.49215650e-02,  2.48933170e-02,  1.86690636e+01,\n",
       "        -5.61819611e+01,  1.09455566e+01, -3.03199616e+00,\n",
       "         8.08849275e-01,  9.82074380e-02, -2.97779152e+00,\n",
       "         5.72443287e-01,  9.17987150e-02,  1.23476673e+00,\n",
       "         1.63280000e+18, -6.21364300e-02,  1.27226669e-01,\n",
       "        -7.19885470e-02, -4.71429559e+00, -6.72220360e-02,\n",
       "        -8.59891146e+00, -2.44880490e-02,  2.00129060e-02,\n",
       "         5.22153710e-02, -1.39453430e+01,  7.57501221e+00,\n",
       "        -5.27445068e+01, -3.87761248e-01, -4.45479990e-02,\n",
       "        -1.87476418e-01, -5.01493490e-01,  9.50407829e-01,\n",
       "        -2.44116765e-01,  6.85479400e-03,  1.63280000e+18,\n",
       "         5.00000000e+00],\n",
       "       [-2.66031219e-01, -6.62976420e-02,  8.48925250e-02,\n",
       "        -5.62811285e-01, -9.73990286e+00, -9.93941187e-01,\n",
       "        -2.14487600e-03,  6.10320120e-02, -3.20495140e-02,\n",
       "         1.03873062e+01, -5.54638901e+01,  9.64025879e+00,\n",
       "         1.12077039e+00,  6.45591704e-01,  2.40580148e-01,\n",
       "        -5.15227528e-01,  7.01995810e-01,  1.80373096e-01,\n",
       "         1.45405712e+00,  1.63280000e+18, -1.09202425e-01,\n",
       "         7.66191300e-03, -4.80944600e-03, -5.37530120e-02,\n",
       "        -9.80383787e+00,  2.28667502e-01, -1.78911460e-02,\n",
       "        -8.31252490e-02,  8.36545900e-03,  2.48997669e+01,\n",
       "        -3.06225700e+01, -2.93501587e+01,  1.64099617e+00,\n",
       "         5.74777925e-01, -4.12880609e-01, -2.91071378e+00,\n",
       "         5.63800441e-01, -4.25780618e-01,  1.54684651e+00,\n",
       "         1.63280000e+18,  1.00000000e+00, -2.66031219e-01,\n",
       "        -6.62976420e-02,  8.48925250e-02, -5.62811285e-01,\n",
       "        -9.73990286e+00, -9.93941187e-01, -2.14487600e-03,\n",
       "         6.10320120e-02, -3.20495140e-02,  1.03873062e+01,\n",
       "        -5.54638901e+01,  9.64025879e+00,  1.12077039e+00,\n",
       "         6.45591704e-01,  2.40580148e-01, -5.15227528e-01,\n",
       "         7.01995810e-01,  1.80373096e-01,  1.45405712e+00,\n",
       "         1.63280000e+18, -1.09202425e-01,  7.66191300e-03,\n",
       "        -4.80944600e-03, -5.37530120e-02, -9.80383787e+00,\n",
       "         2.28667502e-01, -1.78911460e-02, -8.31252490e-02,\n",
       "         8.36545900e-03,  2.48997669e+01, -3.06225700e+01,\n",
       "        -2.93501587e+01,  1.64099617e+00,  5.74777925e-01,\n",
       "        -4.12880609e-01, -2.91071378e+00,  5.63800441e-01,\n",
       "        -4.25780618e-01,  1.54684651e+00,  1.63280000e+18,\n",
       "         1.00000000e+00],\n",
       "       [ 8.86490939e-01,  1.22568980e-01,  4.06166799e-01,\n",
       "        -7.00192123e-01, -9.73214509e+00, -9.82570629e-01,\n",
       "        -2.18002945e-01,  1.64333209e-01,  9.27344780e-02,\n",
       "         1.39302445e+00, -4.34298439e+01,  3.81072998e+00,\n",
       "         1.53791824e+00,  6.11994040e-01,  3.51341906e-01,\n",
       "        -6.19140688e-01,  6.53189039e-01,  2.74528930e-01,\n",
       "         1.44745123e+00,  1.63280000e+18,  5.12416804e-01,\n",
       "        -1.45105806e-01,  6.26197570e-02, -8.32192290e-01,\n",
       "        -9.73950480e+00,  7.87321832e-01,  2.99334270e-02,\n",
       "         2.31115609e-01,  6.22304570e-02,  1.81029415e+01,\n",
       "        -3.78720551e+01, -1.14628296e+01,  1.23644176e+00,\n",
       "         6.11946572e-01, -3.26119073e-01, -2.32849545e+00,\n",
       "         5.94562058e-01, -4.07017977e-01,  1.45370875e+00,\n",
       "         1.63280000e+18,  1.00000000e+00,  8.86490939e-01,\n",
       "         1.22568980e-01,  4.06166799e-01, -7.00192123e-01,\n",
       "        -9.73214509e+00, -9.82570629e-01, -2.18002945e-01,\n",
       "         1.64333209e-01,  9.27344780e-02,  1.39302445e+00,\n",
       "        -4.34298439e+01,  3.81072998e+00,  1.53791824e+00,\n",
       "         6.11994040e-01,  3.51341906e-01, -6.19140688e-01,\n",
       "         6.53189039e-01,  2.74528930e-01,  1.44745123e+00,\n",
       "         1.63280000e+18,  5.12416804e-01, -1.45105806e-01,\n",
       "         6.26197570e-02, -8.32192290e-01, -9.73950480e+00,\n",
       "         7.87321832e-01,  2.99334270e-02,  2.31115609e-01,\n",
       "         6.22304570e-02,  1.81029415e+01, -3.78720551e+01,\n",
       "        -1.14628296e+01,  1.23644176e+00,  6.11946572e-01,\n",
       "        -3.26119073e-01, -2.32849545e+00,  5.94562058e-01,\n",
       "        -4.07017977e-01,  1.45370875e+00,  1.63280000e+18,\n",
       "         1.00000000e+00],\n",
       "       [-2.77952141e-01, -8.54915870e-02,  8.55867180e-02,\n",
       "        -3.33863940e+00, -9.17483269e+00, -9.19966216e-01,\n",
       "        -6.11596370e-02, -1.75532590e-02, -1.67793400e-03,\n",
       "        -7.16086960e+00, -5.43756561e+01, -3.14819336e-01,\n",
       "         2.11724832e+00,  6.56174450e-01,  4.01484736e-01,\n",
       "        -1.30191771e+00,  6.21059877e-01,  1.50099529e-01,\n",
       "         1.20987704e+00,  1.63280000e+18, -3.51949251e-01,\n",
       "        -7.73731630e-02, -5.47813920e-02, -8.24501516e-01,\n",
       "        -9.76653660e+00,  3.24577955e-01,  4.78399690e-02,\n",
       "        -2.31932460e-02,  3.67119500e-03,  9.78992081e+00,\n",
       "        -5.81384582e+01, -2.37632446e+01,  1.47069224e+00,\n",
       "         6.90925169e-01, -1.34563975e-01, -1.94583018e+00,\n",
       "         6.82161060e-01, -1.97917361e-01,  1.48031752e+00,\n",
       "         1.63280000e+18,  1.00000000e+00, -2.77952141e-01,\n",
       "        -8.54915870e-02,  8.55867180e-02, -3.33863940e+00,\n",
       "        -9.17483269e+00, -9.19966216e-01, -6.11596370e-02,\n",
       "        -1.75532590e-02, -1.67793400e-03, -7.16086960e+00,\n",
       "        -5.43756561e+01, -3.14819336e-01,  2.11724832e+00,\n",
       "         6.56174450e-01,  4.01484736e-01, -1.30191771e+00,\n",
       "         6.21059877e-01,  1.50099529e-01,  1.20987704e+00,\n",
       "         1.63280000e+18, -3.51949251e-01, -7.73731630e-02,\n",
       "        -5.47813920e-02, -8.24501516e-01, -9.76653660e+00,\n",
       "         3.24577955e-01,  4.78399690e-02, -2.31932460e-02,\n",
       "         3.67119500e-03,  9.78992081e+00, -5.81384582e+01,\n",
       "        -2.37632446e+01,  1.47069224e+00,  6.90925169e-01,\n",
       "        -1.34563975e-01, -1.94583018e+00,  6.82161060e-01,\n",
       "        -1.97917361e-01,  1.48031752e+00,  1.63280000e+18,\n",
       "         1.00000000e+00],\n",
       "       [ 1.02137890e-02,  1.73117264e-01, -3.43721010e-01,\n",
       "         1.08842499e+00, -9.73451065e+00, -4.74347405e-01,\n",
       "         5.17356920e-02,  5.34981680e-02, -7.56728200e-02,\n",
       "         1.15993309e+01, -4.27852058e+01,  4.86456299e+00,\n",
       "         3.38736590e-01, -4.77459822e-01, -4.63612654e-01,\n",
       "         1.15980455e+00, -5.56100896e-01, -4.97842476e-01,\n",
       "         1.44942727e+00,  1.63280000e+18,  4.35967990e-01,\n",
       "        -1.10310971e-01,  4.98234770e-02, -1.82819596e+00,\n",
       "        -9.62151964e+00, -5.04422261e-01,  2.27921900e-03,\n",
       "         6.51321410e-02, -1.98582340e-02,  1.00935555e+01,\n",
       "        -4.37842483e+01, -1.76671753e+01,  5.36830993e-01,\n",
       "        -6.11274243e-01,  2.07967629e-01, -1.30158191e+00,\n",
       "        -6.94599058e-01,  3.17215103e-01,  1.37618017e+00,\n",
       "         1.63280000e+18,  1.00000000e+00,  1.02137890e-02,\n",
       "         1.73117264e-01, -3.43721010e-01,  1.08842499e+00,\n",
       "        -9.73451065e+00, -4.74347405e-01,  5.17356920e-02,\n",
       "         5.34981680e-02, -7.56728200e-02,  1.15993309e+01,\n",
       "        -4.27852058e+01,  4.86456299e+00,  3.38736590e-01,\n",
       "        -4.77459822e-01, -4.63612654e-01,  1.15980455e+00,\n",
       "        -5.56100896e-01, -4.97842476e-01,  1.44942727e+00,\n",
       "         1.63280000e+18,  4.35967990e-01, -1.10310971e-01,\n",
       "         4.98234770e-02, -1.82819596e+00, -9.62151964e+00,\n",
       "        -5.04422261e-01,  2.27921900e-03,  6.51321410e-02,\n",
       "        -1.98582340e-02,  1.00935555e+01, -4.37842483e+01,\n",
       "        -1.76671753e+01,  5.36830993e-01, -6.11274243e-01,\n",
       "         2.07967629e-01, -1.30158191e+00, -6.94599058e-01,\n",
       "         3.17215103e-01,  1.37618017e+00,  1.63280000e+18,\n",
       "         1.00000000e+00],\n",
       "       [ 1.61594584e-01, -3.39700740e-02,  3.06586115e-01,\n",
       "         5.73125613e-01, -9.78988825e+00,  3.01411000e-03,\n",
       "         1.68486610e-01,  3.23684300e-03,  7.64528810e-02,\n",
       "         4.06433106e+01, -5.59137650e+01,  1.93519001e+01,\n",
       "        -2.35472973e+00,  6.72585585e-01,  2.61268413e-01,\n",
       "         3.13633363e+00,  6.34442743e-01,  2.77218152e-01,\n",
       "         1.51232057e+00,  1.63187000e+18, -7.21829589e-01,\n",
       "        -4.70382300e-02, -6.44464025e-01,  1.12056061e-01,\n",
       "        -9.20939430e+00, -3.36821766e+00,  4.45432901e-01,\n",
       "        -9.46284610e-02,  1.42573510e-02,  2.11123047e+01,\n",
       "        -4.17321930e+01,  8.62443161e+00,  2.37506917e+00,\n",
       "        -6.95332671e-01, -3.74544428e-01, -1.60405271e+00,\n",
       "        -5.94981712e-01, -1.49083016e-01,  1.21999277e+00,\n",
       "         1.63187000e+18,  1.00000000e+00,  1.61594584e-01,\n",
       "        -3.39700740e-02,  3.06586115e-01,  5.73125613e-01,\n",
       "        -9.78988825e+00,  3.01411000e-03,  1.68486610e-01,\n",
       "         3.23684300e-03,  7.64528810e-02,  4.06433106e+01,\n",
       "        -5.59137650e+01,  1.93519001e+01, -2.35472973e+00,\n",
       "         6.72585585e-01,  2.61268413e-01,  3.13633363e+00,\n",
       "         6.34442743e-01,  2.77218152e-01,  1.51232057e+00,\n",
       "         1.63187000e+18, -7.21829589e-01, -4.70382300e-02,\n",
       "        -6.44464025e-01,  1.12056061e-01, -9.20939430e+00,\n",
       "        -3.36821766e+00,  4.45432901e-01, -9.46284610e-02,\n",
       "         1.42573510e-02,  2.11123047e+01, -4.17321930e+01,\n",
       "         8.62443161e+00,  2.37506917e+00, -6.95332671e-01,\n",
       "        -3.74544428e-01, -1.60405271e+00, -5.94981712e-01,\n",
       "        -1.49083016e-01,  1.21999277e+00,  1.63187000e+18,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并训练数据和测试数据\n",
    "X_train_all, y_train_all = pd.concat([data[0] for data in all_train_data]), pd.concat([data[1] for data in all_train_data])\n",
    "X_test_all, y_test_all = pd.concat([data[0] for data in all_test_data]), pd.concat([data[1] for data in all_test_data])\n",
    "\n",
    "# 使用SMOTE处理类别不平衡\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_all, y_train_all)\n",
    "\n",
    "# 划分训练集和验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# 定义XGBoost和LightGBM的参数空间\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'tree_method': 'gpu_hist',\n",
    "}\n",
    "\n",
    "lgbm_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'num_leaves': [31, 50, 100],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'tree_method': 'gpu_hist',\n",
    "}\n",
    "\n",
    "# 使用 RandomizedSearchCV 进行XGBoost模型调优\n",
    "xgb_clf = XGBClassifier(n_jobs=-1, random_state=42)\n",
    "xgb_random_search = RandomizedSearchCV(xgb_clf, xgb_param_grid, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "xgb_random_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best parameters for XGBoost:\", xgb_random_search.best_params_)\n",
    "best_xgb_clf = xgb_random_search.best_estimator_\n",
    "\n",
    "# 使用 RandomizedSearchCV 进行LightGBM模型调优\n",
    "lgbm_clf = LGBMClassifier(n_jobs=-1, random_state=42)\n",
    "lgbm_random_search = RandomizedSearchCV(lgbm_clf, lgbm_param_grid, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "lgbm_random_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best parameters for LightGBM:\", lgbm_random_search.best_params_)\n",
    "best_lgbm_clf = lgbm_random_search.best_estimator_\n",
    "\n",
    "# 在验证集上评估XGBoost模型\n",
    "y_pred_xgb = best_xgb_clf.predict(X_val)\n",
    "print(\"XGBoost Validation Accuracy:\", accuracy_score(y_val, y_pred_xgb))\n",
    "print(\"XGBoost Classification Report:\\n\", classification_report(y_val, y_pred_xgb))\n",
    "\n",
    "# 在验证集上评估LightGBM模型\n",
    "y_pred_lgbm = best_lgbm_clf.predict(X_val)\n",
    "print(\"LightGBM Validation Accuracy:\", accuracy_score(y_val, y_pred_lgbm))\n",
    "print(\"LightGBM Classification Report:\\n\", classification_report(y_val, y_pred_lgbm))\n",
    "\n",
    "# 对测试集进行预测\n",
    "y_pred_xgb_test = best_xgb_clf.predict(X_test_all)\n",
    "print(\"XGBoost Test Accuracy:\", accuracy_score(y_test_all, y_pred_xgb_test))\n",
    "print(\"XGBoost Test Classification Report:\\n\", classification_report(y_test_all, y_pred_xgb_test))\n",
    "\n",
    "y_pred_lgbm_test = best_lgbm_clf.predict(X_test_all)\n",
    "print(\"LightGBM Test Accuracy:\", accuracy_score(y_test_all, y_pred_lgbm_test))\n",
    "print(\"LightGBM Test Classification Report:\\n\", classification_report(y_test_all, y_pred_lgbm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python3.9.0\\PYTHON\\lib\\site-packages\\sklearn\\impute\\_base.py:577: UserWarning: Skipping features without any observed values: ['Accelerometer.xlsx_z_xd_std_1' 'Accelerometer.xlsx_y_xd_std_1'\n",
      " 'Accelerometer.xlsx_x_xd_std_1' 'Gravity_z_xd_std_1' 'Gravity_y_xd_std_1'\n",
      " 'Gravity_x_xd_std_1' 'Gyroscope_z_xd_std_1' 'Gyroscope_y_xd_std_1'\n",
      " 'Gyroscope_x_xd_std_1' 'Magnetometer_z_xd_std_1'\n",
      " 'Magnetometer_y_xd_std_1' 'Magnetometer_x_xd_std_1' 'yaw_xd_std_1'\n",
      " 'qx_xd_std_1' 'qz_xd_std_1' 'roll_xd_std_1' 'qw_xd_std_1' 'qy_xd_std_1'\n",
      " 'pitch_xd_std_1' 'time_xd_std_1' 'Accelerometer.xlsx_z_kd_std_1'\n",
      " 'Accelerometer.xlsx_y_kd_std_1' 'Accelerometer.xlsx_x_kd_std_1'\n",
      " 'Gravity_z_kd_std_1' 'Gravity_y_kd_std_1' 'Gravity_x_kd_std_1'\n",
      " 'Gyroscope_z_kd_std_1' 'Gyroscope_y_kd_std_1' 'Gyroscope_x_kd_std_1'\n",
      " 'Magnetometer_z_kd_std_1' 'Magnetometer_y_kd_std_1'\n",
      " 'Magnetometer_x_kd_std_1' 'yaw_kd_std_1' 'qx_kd_std_1' 'qz_kd_std_1'\n",
      " 'roll_kd_std_1' 'qw_kd_std_1' 'qy_kd_std_1' 'pitch_kd_std_1'\n",
      " 'time_kd_std_1' 'Label_2_kd_std_1']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "d:\\python3.9.0\\PYTHON\\lib\\site-packages\\sklearn\\impute\\_base.py:577: UserWarning: Skipping features without any observed values: ['Accelerometer.xlsx_z_xd_std_1' 'Accelerometer.xlsx_y_xd_std_1'\n",
      " 'Accelerometer.xlsx_x_xd_std_1' 'Gravity_z_xd_std_1' 'Gravity_y_xd_std_1'\n",
      " 'Gravity_x_xd_std_1' 'Gyroscope_z_xd_std_1' 'Gyroscope_y_xd_std_1'\n",
      " 'Gyroscope_x_xd_std_1' 'Magnetometer_z_xd_std_1'\n",
      " 'Magnetometer_y_xd_std_1' 'Magnetometer_x_xd_std_1' 'yaw_xd_std_1'\n",
      " 'qx_xd_std_1' 'qz_xd_std_1' 'roll_xd_std_1' 'qw_xd_std_1' 'qy_xd_std_1'\n",
      " 'pitch_xd_std_1' 'time_xd_std_1' 'Accelerometer.xlsx_z_kd_std_1'\n",
      " 'Accelerometer.xlsx_y_kd_std_1' 'Accelerometer.xlsx_x_kd_std_1'\n",
      " 'Gravity_z_kd_std_1' 'Gravity_y_kd_std_1' 'Gravity_x_kd_std_1'\n",
      " 'Gyroscope_z_kd_std_1' 'Gyroscope_y_kd_std_1' 'Gyroscope_x_kd_std_1'\n",
      " 'Magnetometer_z_kd_std_1' 'Magnetometer_y_kd_std_1'\n",
      " 'Magnetometer_x_kd_std_1' 'yaw_kd_std_1' 'qx_kd_std_1' 'qz_kd_std_1'\n",
      " 'roll_kd_std_1' 'qw_kd_std_1' 'qy_kd_std_1' 'pitch_kd_std_1'\n",
      " 'time_kd_std_1' 'Label_2_kd_std_1']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10, 5]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 95\u001b[0m\n\u001b[0;32m     88\u001b[0m X_test_imputed \u001b[38;5;241m=\u001b[39m imputer\u001b[38;5;241m.\u001b[39mtransform(X_test_all)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# # 使用SMOTE处理类别不平衡\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# smote = SMOTE(random_state=42, k_neighbors=2)  # 设置 k_neighbors 为 2\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# X_resampled, y_resampled = smote.fit_resample(X_train_imputed, y_train_all)\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# 划分训练集和验证集\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_imputed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_imputed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# 定义XGBoost和LightGBM的参数空间\u001b[39;00m\n\u001b[0;32m     98\u001b[0m xgb_param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m],\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m7\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m1.0\u001b[39m],\n\u001b[0;32m    104\u001b[0m }\n",
      "File \u001b[1;32md:\\python3.9.0\\PYTHON\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32md:\\python3.9.0\\PYTHON\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2657\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2657\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2659\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2660\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2661\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2662\u001b[0m )\n",
      "File \u001b[1;32md:\\python3.9.0\\PYTHON\\lib\\site-packages\\sklearn\\utils\\validation.py:514\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <3x1 sparse matrix ...>]\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 514\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\python3.9.0\\PYTHON\\lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10, 5]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 定义滑窗长度列表（假设采样频率为1Hz）\n",
    "sampling_frequency = 1  # 每秒一个样本\n",
    "window_lengths = [max(int(0.6 * sampling_frequency), 1), max(int(0.8 * sampling_frequency), 1), max(int(1 * sampling_frequency), 1)]\n",
    "\n",
    "# 定义要处理的主题\n",
    "train_subjects = ['Carpenter1', 'Carpenter2', 'Rebar1', 'Rebar2', 'Rebar3']\n",
    "test_subjects = ['Masonry1', 'Masonry2']\n",
    "\n",
    "# 初始化空数据框存储所有主题的数据\n",
    "all_train_data = []\n",
    "all_test_data = []\n",
    "\n",
    "# 遍历每个主题文件\n",
    "for subject in train_subjects + test_subjects:\n",
    "    # 读取数据，设置 low_memory=False\n",
    "    df = pd.read_csv(f'../{subject}.csv', low_memory=False)\n",
    "    \n",
    "    # 将 'Label_2' 列转换为数值类型\n",
    "    df['Label_2'] = pd.to_numeric(df['Label_2'], errors='coerce')\n",
    "    \n",
    "    # 只选取前八个动作\n",
    "    df = df[df['Label_2'] <= 8]\n",
    "    \n",
    "    # 重新编码标签\n",
    "    label_mapping = {1: 1, 2: 2, 3: 3, 4: 3, 5: 4, 6: 3, 7: 3, 8: 5}\n",
    "    df['Label_2'] = df['Label_2'].map(label_mapping)\n",
    "    \n",
    "    # 同步 xd 和 kd 的记录\n",
    "    df_xd = df[df['position'] == 'xd'].copy()\n",
    "    df_kd = df[df['position'] == 'kd'].copy()\n",
    "\n",
    "    # 确保 xd 和 kd 有相同的时间戳\n",
    "    common_times = set(df_xd['seconds_elapsed']).intersection(set(df_kd['seconds_elapsed']))\n",
    "    df_xd = df_xd[df_xd['seconds_elapsed'].isin(common_times)]\n",
    "    df_kd = df_kd[df_kd['seconds_elapsed'].isin(common_times)]\n",
    "\n",
    "    # 将 xd 和 kd 的数据合并为一个数据单元\n",
    "    df_combined = pd.merge(df_xd, df_kd, on='seconds_elapsed', suffixes=('_xd', '_kd'))\n",
    "\n",
    "    # 删除非数值列\n",
    "    df_combined = df_combined.select_dtypes(include=[np.number])\n",
    "\n",
    "    # 删除包含NaN的行\n",
    "    df_combined.dropna(inplace=True)\n",
    "\n",
    "    # 检查并替换inf值为NaN，然后删除包含NaN的行\n",
    "    df_combined.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_combined.dropna(inplace=True)\n",
    "\n",
    "    # 创建不同滑窗长度的特征\n",
    "    new_features = {}\n",
    "    for window_length in window_lengths:\n",
    "        for col in df_combined.columns:\n",
    "            if col not in ['seconds_elapsed', 'Label_2_xd']:\n",
    "                # 确保窗口大小至少为1\n",
    "                window_length = max(window_length, 1)\n",
    "                new_features[f'{col}_mean_{window_length}'] = df_combined[col].rolling(window=window_length, min_periods=1).mean()\n",
    "                new_features[f'{col}_std_{window_length}'] = df_combined[col].rolling(window=window_length, min_periods=1).std()\n",
    "\n",
    "    # 一次性将所有新特征添加到 DataFrame 中\n",
    "    df_combined = pd.concat([df_combined, pd.DataFrame(new_features)], axis=1)\n",
    "\n",
    "    # 分离特征和目标变量\n",
    "    X = df_combined.drop(columns=['seconds_elapsed', 'Label_2_xd'])\n",
    "    y = df_combined['Label_2_xd']\n",
    "\n",
    "    if subject in train_subjects:\n",
    "        all_train_data.append((X, y))\n",
    "    else:\n",
    "        all_test_data.append((X, y))\n",
    "\n",
    "# 合并训练数据和测试数据\n",
    "X_train_all, y_train_all = pd.concat([data[0] for data in all_train_data]), pd.concat([data[1] for data in all_train_data])\n",
    "X_test_all, y_test_all = pd.concat([data[0] for data in all_test_data]), pd.concat([data[1] for data in all_test_data])\n",
    "\n",
    "# 使用 SimpleImputer 处理缺失值\n",
    "imputer = SimpleImputer(strategy='mean')  # 也可以选择其他策略，如 'median' 或 'most_frequent'\n",
    "X_train_imputed = imputer.fit_transform(X_train_all)\n",
    "X_test_imputed = imputer.transform(X_test_all)\n",
    "\n",
    "# # 使用SMOTE处理类别不平衡\n",
    "# smote = SMOTE(random_state=42, k_neighbors=2)  # 设置 k_neighbors 为 2\n",
    "# X_resampled, y_resampled = smote.fit_resample(X_train_imputed, y_train_all)\n",
    "\n",
    "# 划分训练集和验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_imputed, X_test_imputed, test_size=0.2, random_state=42)\n",
    "\n",
    "# 定义XGBoost和LightGBM的参数空间\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "lgbm_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'num_leaves': [31, 50, 100],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "# 使用 RandomizedSearchCV 进行XGBoost模型调优\n",
    "xgb_clf = XGBClassifier(n_jobs=-1, random_state=42)\n",
    "xgb_random_search = RandomizedSearchCV(xgb_clf, xgb_param_grid, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "xgb_random_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best parameters for XGBoost:\", xgb_random_search.best_params_)\n",
    "best_xgb_clf = xgb_random_search.best_estimator_\n",
    "\n",
    "# 使用 RandomizedSearchCV 进行LightGBM模型调优\n",
    "lgbm_clf = LGBMClassifier(n_jobs=-1, random_state=42)\n",
    "lgbm_random_search = RandomizedSearchCV(lgbm_clf, lgbm_param_grid, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "lgbm_random_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best parameters for LightGBM:\", lgbm_random_search.best_params_)\n",
    "best_lgbm_clf = lgbm_random_search.best_estimator_\n",
    "\n",
    "# 在验证集上评估XGBoost模型\n",
    "y_pred_xgb = best_xgb_clf.predict(X_val)\n",
    "print(\"XGBoost Validation Accuracy:\", accuracy_score(y_val, y_pred_xgb))\n",
    "print(\"XGBoost Classification Report:\\n\", classification_report(y_val, y_pred_xgb))\n",
    "\n",
    "# 在验证集上评估LightGBM模型\n",
    "y_pred_lgbm = best_lgbm_clf.predict(X_val)\n",
    "print(\"LightGBM Validation Accuracy:\", accuracy_score(y_val, y_pred_lgbm))\n",
    "print(\"LightGBM Classification Report:\\n\", classification_report(y_val, y_pred_lgbm))\n",
    "\n",
    "# 对测试集进行预测\n",
    "y_pred_xgb_test = best_xgb_clf.predict(X_test_imputed)\n",
    "print(\"XGBoost Test Accuracy:\", accuracy_score(y_test_all, y_pred_xgb_test))\n",
    "print(\"XGBoost Test Classification Report:\\n\", classification_report(y_test_all, y_pred_xgb_test))\n",
    "\n",
    "y_pred_lgbm_test = best_lgbm_clf.predict(X_test_imputed)\n",
    "print(\"LightGBM Test Accuracy:\", accuracy_score(y_test_all, y_pred_lgbm_test))\n",
    "print(\"LightGBM Test Classification Report:\\n\", classification_report(y_test_all, y_pred_lgbm_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
